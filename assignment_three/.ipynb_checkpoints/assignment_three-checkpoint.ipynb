{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I'll just be using the Titanic data set for my classification assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "df = pd.read_csv('../data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass                                               name  \\\n",
       "0         0       3                            Braund, Mr. Owen Harris   \n",
       "1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2         1       3                             Heikkinen, Miss. Laina   \n",
       "3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4         0       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      sex   age  sibsp  parch            ticket     fare cabin embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "survived    891 non-null int64\n",
      "pclass      891 non-null int64\n",
      "name        891 non-null object\n",
      "sex         891 non-null object\n",
      "age         714 non-null float64\n",
      "sibsp       891 non-null int64\n",
      "parch       891 non-null int64\n",
      "ticket      891 non-null object\n",
      "fare        891 non-null float64\n",
      "cabin       204 non-null object\n",
      "embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 76.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First things first, cleaning up the data a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass  sex   \n",
       "1       female    35.0\n",
       "        male      40.0\n",
       "2       female    28.0\n",
       "        male      30.0\n",
       "3       female    21.5\n",
       "        male      25.0\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['pclass','sex'])['age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass  sex   \n",
       "1       female    34.611765\n",
       "        male      41.281386\n",
       "2       female    28.722973\n",
       "        male      30.740707\n",
       "3       female    21.750000\n",
       "        male      26.507589\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['pclass','sex'])['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median and mean age within different sex/class groups are pretty different so I'll replace nulls with the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df.groupby(['pclass','sex'])['age'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin is null for the majority of data points so I will choose to disregard it and take it out of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('cabin',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked has 2 null values so I'll just replace them with the most commonly occurring value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: embarked, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.embarked = df.embarked.fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    646\n",
       "C    168\n",
       "Q     77\n",
       "Name: embarked, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.embarked.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm interested in creating a variable based on the title of the passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "names = df.name\n",
    "title = []\n",
    "for i in names:\n",
    "    j = re.search(', (.*)\\.', i)\n",
    "    if j:\n",
    "        title.append(j.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "title1 = []\n",
    "for i in title:\n",
    "    j = i[2:]\n",
    "    title1.append(j)\n",
    "title2 = []\n",
    "for i in title1:\n",
    "    j = i[:-1]\n",
    "    title2.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = title2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Rothschild, Mrs. Martin (Elizabeth L. Barrett)</td>\n",
       "      <td>female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17603</td>\n",
       "      <td>59.4</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs. Martin (Elizabeth L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass                                            name     sex  \\\n",
       "513         1       1  Rothschild, Mrs. Martin (Elizabeth L. Barrett)  female   \n",
       "\n",
       "      age  sibsp  parch    ticket  fare embarked                     title  \n",
       "513  54.0      1      0  PC 17603  59.4        C  Mrs. Martin (Elizabeth L  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.title=='Mrs. Martin (Elizabeth L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr                          517\n",
       "Miss                        182\n",
       "Mrs                         124\n",
       "Master                       40\n",
       "Dr                            7\n",
       "Rev                           6\n",
       "Col                           2\n",
       "Mlle                          2\n",
       "Major                         2\n",
       "Ms                            1\n",
       "Capt                          1\n",
       "Lady                          1\n",
       "Don                           1\n",
       "Mme                           1\n",
       "Sir                           1\n",
       "Mrs. Martin (Elizabeth L      1\n",
       "Jonkheer                      1\n",
       "the Countess                  1\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to use my own judgment to group the rarer ones down further\n",
    "df = df.replace({'title' : {'Master': 'Uppity','Dr':'Uppity','Rev':'Uppity','Mlle':'Uppity','Col':'Uppity'\n",
    "                            ,'Major':'Uppity','Capt':'Uppity','Ms':'Miss','the Countess':'Uppity','Sir':'Uppity'\n",
    "                            ,'Lady':'Uppity','Jonkheer':'Uppity','Mrs. Martin (Elizabeth L':'Mrs'\n",
    "                            ,'Mme':'Uppity','Don':'Uppity'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        517\n",
       "Miss      183\n",
       "Mrs       125\n",
       "Uppity     66\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'sex':{'female':0,'male':1}\n",
    "                ,'embarked':{'C':'Cherbourg','Q':'Queenstown','S':'Southampton'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass  title \n",
       "1       Mr        107\n",
       "        Miss       46\n",
       "        Mrs        42\n",
       "        Uppity     21\n",
       "2       Mr         91\n",
       "        Mrs        41\n",
       "        Miss       35\n",
       "        Uppity     17\n",
       "3       Mr        319\n",
       "        Miss      102\n",
       "        Mrs        42\n",
       "        Uppity     28\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('pclass')['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title   sex  survived\n",
       "Miss    0    1           128\n",
       "             0            55\n",
       "Mr      1    0           436\n",
       "             1            81\n",
       "Mrs     0    1            99\n",
       "             0            26\n",
       "Uppity  0    1             6\n",
       "        1    0            32\n",
       "             1            28\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['title','sex'])['survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Of the titles, it seems like uppity men survived at a much higher rate than normal men so I'll create a dummy variable that only looks at whether they were uppity people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = []\n",
    "t = df.title\n",
    "for i in t:\n",
    "    if i == 'Uppity':\n",
    "        u.append(1)\n",
    "    else:\n",
    "        u.append(0)\n",
    "df['uppity'] = u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'll create a family size variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['famsize'] = df['sibsp'] + df['parch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Women and children were prioritized to get off first (according to the movie) so I'll create a variable for children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "a = df.age\n",
    "for i in a:\n",
    "    if i < 18:\n",
    "        c.append(1)\n",
    "    else:\n",
    "        c.append(0)\n",
    "df['child'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "child  survived\n",
       "0      0           497\n",
       "       1           281\n",
       "1      1            61\n",
       "       0            52\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('child')['survived'].value_counts()\n",
    "#it looks like being a child didn't really guarantee your survival...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore the data  bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embarked     survived\n",
       "Cherbourg    1            93\n",
       "             0            75\n",
       "Queenstown   0            47\n",
       "             1            30\n",
       "Southampton  0           427\n",
       "             1           219\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('embarked')['survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "famsize  survived\n",
       "0        0           374\n",
       "         1           163\n",
       "1        1            89\n",
       "         0            72\n",
       "2        1            59\n",
       "         0            43\n",
       "3        1            21\n",
       "         0             8\n",
       "4        0            12\n",
       "         1             3\n",
       "5        0            19\n",
       "         1             3\n",
       "6        0             8\n",
       "         1             4\n",
       "7        0             6\n",
       "10       0             7\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('famsize')['survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.survived.value_counts()\n",
    "#This means that my classifier should do better than a score of 0.62\n",
    "#since that's the result if you guess that no one survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass  survived\n",
       "1       1           136\n",
       "        0            80\n",
       "2       0            97\n",
       "        1            87\n",
       "3       0           372\n",
       "        1           119\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('pclass')['survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm ready to start trying to classify!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "survived    891 non-null int64\n",
      "pclass      891 non-null int64\n",
      "name        891 non-null object\n",
      "sex         891 non-null int64\n",
      "age         891 non-null float64\n",
      "sibsp       891 non-null int64\n",
      "parch       891 non-null int64\n",
      "ticket      891 non-null object\n",
      "fare        891 non-null float64\n",
      "embarked    891 non-null object\n",
      "title       891 non-null object\n",
      "uppity      891 non-null int64\n",
      "famsize     891 non-null int64\n",
      "child       891 non-null int64\n",
      "dtypes: float64(2), int64(8), object(4)\n",
      "memory usage: 97.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy variable time\n",
    "dfwd = pd.get_dummies(df,columns = ['embarked','title','pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 21 columns):\n",
      "survived                891 non-null int64\n",
      "name                    891 non-null object\n",
      "sex                     891 non-null int64\n",
      "age                     891 non-null float64\n",
      "sibsp                   891 non-null int64\n",
      "parch                   891 non-null int64\n",
      "ticket                  891 non-null object\n",
      "fare                    891 non-null float64\n",
      "uppity                  891 non-null int64\n",
      "famsize                 891 non-null int64\n",
      "child                   891 non-null int64\n",
      "embarked_Cherbourg      891 non-null uint8\n",
      "embarked_Queenstown     891 non-null uint8\n",
      "embarked_Southampton    891 non-null uint8\n",
      "title_Miss              891 non-null uint8\n",
      "title_Mr                891 non-null uint8\n",
      "title_Mrs               891 non-null uint8\n",
      "title_Uppity            891 non-null uint8\n",
      "pclass_1                891 non-null uint8\n",
      "pclass_2                891 non-null uint8\n",
      "pclass_3                891 non-null uint8\n",
      "dtypes: float64(2), int64(7), object(2), uint8(10)\n",
      "memory usage: 85.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dfwd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfwd.drop(['pclass_3','title_Uppity','title_Miss','embarked_Southampton','ticket','name','survived'],axis=1)\n",
    "y = dfwd.survived\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, a Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.58      0.58       133\n",
      "          1       0.38      0.38      0.38        90\n",
      "\n",
      "avg / total       0.50      0.50      0.50       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dum = DummyClassifier()\n",
    "dum.fit(X_train,y_train)\n",
    "print(classification_report(y_test,dum.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, a KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.86      0.79       133\n",
      "          1       0.71      0.52      0.60        90\n",
      "\n",
      "avg / total       0.72      0.72      0.71       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "knc.fit(X_train,y_train)\n",
    "print(classification_report(y_test,knc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now with GridSearch for neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kncparams = {'kneighborsclassifier__n_neighbors':[i for i in range (1,7)]}\n",
    "kncpipe = make_pipeline(KNeighborsClassifier())\n",
    "kncgrid = GridSearchCV(kncpipe,param_grid=kncparams,cv=5)\n",
    "kncgrid.fit(X_train,y_train)\n",
    "kncgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.86      0.79       133\n",
      "          1       0.71      0.52      0.60        90\n",
      "\n",
      "avg / total       0.72      0.72      0.71       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,kncgrid.predict(X_test)))\n",
    "#this is worse lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kncpipes = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "kncgrids = GridSearchCV(kncpipes,param_grid=kncparams,cv=5)\n",
    "kncgrids.fit(X_train,y_train)\n",
    "kncgrids.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.83      0.81       133\n",
      "          1       0.73      0.68      0.70        90\n",
      "\n",
      "avg / total       0.77      0.77      0.77       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,kncgrids.predict(X_test)))\n",
    "#scaling the data made it better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now a logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85       133\n",
      "          1       0.80      0.72      0.76        90\n",
      "\n",
      "avg / total       0.82      0.82      0.81       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "print(classification_report(y_test,lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'logisticregression__C': [0.1,1,5,10,100]\n",
    "         ,'logisticregression__penalty': ['l1','l2']}\n",
    "lrpipe = make_pipeline(LogisticRegression())\n",
    "lrgrid = GridSearchCV(lrpipe,param_grid=params,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'logisticregression__C': [0.1, 1, 5, 10, 100], 'logisticregression__penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrgrid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('logisticregression', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85       133\n",
      "          1       0.80      0.71      0.75        90\n",
      "\n",
      "avg / total       0.81      0.81      0.81       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lrgrid.predict(X_test)\n",
    "print(classification_report(y_test,pred))\n",
    "#using l1 as the penalty made it worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score:  0.8116591928251121 \n",
      "Train set accuracy score:  0.8278443113772455\n"
     ]
    }
   ],
   "source": [
    "print('Test set accuracy score: ',accuracy_score(y_test,pred), '\\nTrain set accuracy score: ',accuracy_score(lrgrid.predict(X_train),y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('polynomialfeatures', PolynomialFeatures(degree=1, include_bias=True, interaction_only=False)), ('logisticregression', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrparams = {'polynomialfeatures__degree':[i for i in range (1,4)]\n",
    "           ,'logisticregression__penalty':['l1','l2']\n",
    "           ,'logisticregression__C':[.1,1,5,10]}\n",
    "lrpipep = make_pipeline(PolynomialFeatures(),LogisticRegression())\n",
    "lrgridp = GridSearchCV(lrpipep,param_grid = lrparams,cv=5)\n",
    "lrgridp.fit(X_train,y_train)\n",
    "lrgridp.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85       133\n",
      "          1       0.80      0.71      0.75        90\n",
      "\n",
      "avg / total       0.81      0.81      0.81       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,lrgridp.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This time I want to use the variables that my exploration and gut say would have an effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 21 columns):\n",
      "survived                891 non-null int64\n",
      "name                    891 non-null object\n",
      "sex                     891 non-null int64\n",
      "age                     891 non-null float64\n",
      "sibsp                   891 non-null int64\n",
      "parch                   891 non-null int64\n",
      "ticket                  891 non-null object\n",
      "fare                    891 non-null float64\n",
      "uppity                  891 non-null int64\n",
      "famsize                 891 non-null int64\n",
      "child                   891 non-null int64\n",
      "embarked_Cherbourg      891 non-null uint8\n",
      "embarked_Queenstown     891 non-null uint8\n",
      "embarked_Southampton    891 non-null uint8\n",
      "title_Miss              891 non-null uint8\n",
      "title_Mr                891 non-null uint8\n",
      "title_Mrs               891 non-null uint8\n",
      "title_Uppity            891 non-null uint8\n",
      "pclass_1                891 non-null uint8\n",
      "pclass_2                891 non-null uint8\n",
      "pclass_3                891 non-null uint8\n",
      "dtypes: float64(2), int64(7), object(2), uint8(10)\n",
      "memory usage: 85.3+ KB\n"
     ]
    }
   ],
   "source": [
    "dfwd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = dfwd[['sex','uppity','famsize','child','embarked_Cherbourg','pclass_1']]\n",
    "y1 = dfwd.survived\n",
    "X1_train,X1_test,y1_train,y1_test = train_test_split(X1,y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kncparams = {'kneighborsclassifier__n_neighbors':[i for i in range (1,7)]}\n",
    "kncpipe = make_pipeline(KNeighborsClassifier())\n",
    "kncgrid1 = GridSearchCV(kncpipe,param_grid=kncparams,cv=5)\n",
    "kncgrid1.fit(X1_train,y1_train)\n",
    "kncgrid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.89      0.84       132\n",
      "          1       0.81      0.65      0.72        91\n",
      "\n",
      "avg / total       0.80      0.79      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1_test,kncgrid1.predict(X1_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kncgrids.fit(X1_train,y1_train)\n",
    "kncgrids.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.89      0.84       132\n",
      "          1       0.81      0.67      0.73        91\n",
      "\n",
      "avg / total       0.80      0.80      0.80       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1_test,kncgrids.predict(X1_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrparams = {'logisticregression__C': [0.1,1,5,10,100]\n",
    "         ,'logisticregression__penalty': ['l1','l2']}\n",
    "lrpipe = make_pipeline(LogisticRegression())\n",
    "lrgrid1 = GridSearchCV(lrpipe,param_grid=params,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('logisticregression', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrgrid1.fit(X1_train,y1_train)\n",
    "lrgrid1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.89      0.84       132\n",
      "          1       0.80      0.67      0.73        91\n",
      "\n",
      "avg / total       0.80      0.80      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1_test,lrgrid1.predict(X1_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('polynomialfeatures', PolynomialFeatures(degree=3, include_bias=True, interaction_only=False)), ('logisticregression', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrgridp.fit(X1_train,y1_train)\n",
    "lrgridp.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.90      0.86       132\n",
      "          1       0.83      0.70      0.76        91\n",
      "\n",
      "avg / total       0.82      0.82      0.82       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y1_test,lrgridp.predict(X1_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score:  0.820627802690583 \n",
      "Train set accuracy score:  0.8323353293413174\n"
     ]
    }
   ],
   "source": [
    "print('Test set accuracy score: ',accuracy_score(y1_test,lrgridp.predict(X1_test)), '\\nTrain set accuracy score: ',accuracy_score(lrgridp.predict(X1_train),y1_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just playing around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('logisticregression', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'logisticregression__C': [0.1,1,5,10,100]}\n",
    "pipe = make_pipeline(LogisticRegression(penalty='l1'))\n",
    "grid = GridSearchCV(pipe,param_grid=params,cv=5)\n",
    "grid.fit(X1_train,y1_train)\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.89      0.84       132\n",
      "          1       0.80      0.67      0.73        91\n",
      "\n",
      "avg / total       0.80      0.80      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = grid.predict(X1_test)\n",
    "print(classification_report(y1_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('logisticregression', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'logisticregression__C': [0.1,1,5,10,100]}\n",
    "pipe = make_pipeline(LogisticRegression(penalty='l2'))\n",
    "grid = GridSearchCV(pipe,param_grid=params,cv=5)\n",
    "grid.fit(X1_train,y1_train)\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.89      0.84       132\n",
      "          1       0.80      0.67      0.73        91\n",
      "\n",
      "avg / total       0.80      0.80      0.79       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = grid.predict(X1_test)\n",
    "print(classification_report(y1_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "#### In the Titanic data set, I think that the best score to use would be accuracy since there aren't any general risks associated with incorrectly classifying someone either positively or negatively so getting the highest number of test cases correctly would be best. Using this criteria, among the models that I had created, using all of the available variables with an l1 penalty resulted in very similar results to using all available variables with an l2 penalty, and since using the l1 penalty means feature selecting is occurring I take this to mean that all of the features help us in making the model as accurate as possible. Using a grid search with PolynomialFeatures found that degree = 1 was the best fit.\n",
    "\n",
    "### Overall, the best model based on accuracy scores was actually the logistic regression model with polynomial features (degree=3) using the X with variables that I had selected myself. The accuracy in the training set was also not significantly higher than in the test set so it doesn't seem that there was an issue with overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
